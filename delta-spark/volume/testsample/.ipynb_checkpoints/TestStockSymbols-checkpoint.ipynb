{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3bf27a3-48c5-47b8-91b1-7fd6a3ca5e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+-----------+\n",
      "|namespace|       tableName|isTemporary|\n",
      "+---------+----------------+-----------+\n",
      "|  default|teststocksymbols|      false|\n",
      "+---------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show tables in the current database\n",
    "\n",
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0567d718-3284-4687-bba1-b9cada7f6612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/08/06 23:22:17 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `default`.`teststocksymbols` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestStockSymbols\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the schema for the table\n",
    "schema = \"symbol STRING, name STRING, price DOUBLE, volume INT\"\n",
    "\n",
    "# Create a DataFrame with sample data\n",
    "data = [\n",
    "    (\"AAPL\", \"Apple Inc.\", 175.64, 3000000),\n",
    "    (\"MSFT\", \"Microsoft Corp.\", 341.07, 2500000),\n",
    "    (\"GOOGL\", \"Alphabet Inc.\", 2724.34, 1800000)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Write DataFrame to Delta table in HDFS\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"hdfs://namenode:8020/testlakehouse/TestStockSymbols\")\n",
    "\n",
    "# Drop the existing table if it exists\n",
    "spark.sql(\"DROP TABLE IF EXISTS TestStockSymbols\")\n",
    "\n",
    "# Register the Delta table in Spark SQL catalog\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE TestStockSymbols\n",
    "    USING DELTA\n",
    "    LOCATION 'hdfs://namenode:8020/testlakehouse/TestStockSymbols'\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dce07909-4e61-4417-a89d-1b9c9bac8f81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+-----------+\n",
      "|namespace|       tableName|isTemporary|\n",
      "+---------+----------------+-----------+\n",
      "|  default|teststocksymbols|      false|\n",
      "+---------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show tables in the current database\n",
    "\n",
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffb85fa5-1dc3-4d62-9eb9-1c5a55026b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+-------+-------+\n",
      "|symbol|           name|  price| volume|\n",
      "+------+---------------+-------+-------+\n",
      "|  MSFT|Microsoft Corp.| 341.07|2500000|\n",
      "| GOOGL|  Alphabet Inc.|2724.34|1800000|\n",
      "|  AAPL|     Apple Inc.| 175.64|3000000|\n",
      "+------+---------------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query to select all records from the test_table\n",
    "result = spark.sql(\"SELECT * FROM teststocksymbols\")\n",
    "\n",
    "# Show the results\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6238a844-ce42-4bc7-9489-68849c7e4af4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with additional sample data\n",
    "additional_data = [\n",
    "    (\"TSLA\", \"Tesla Inc.\", 890.10, 2000000),\n",
    "    (\"AMZN\", \"Amazon.com Inc.\", 139.68, 2200000),\n",
    "    (\"NVDA\", \"NVIDIA Corporation\", 585.54, 1500000)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "additional_df = spark.createDataFrame(additional_data, schema=schema)\n",
    "\n",
    "# Append data to the Delta table in HDFS\n",
    "additional_df.write.format(\"delta\").mode(\"append\").save(\"hdfs://namenode:8020/testlakehouse/TestStockSymbols\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f9f8e57-0c06-4f92-8990-7c1b675594c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+-------+-------+\n",
      "|symbol|              name|  price| volume|\n",
      "+------+------------------+-------+-------+\n",
      "|  NVDA|NVIDIA Corporation| 585.54|1500000|\n",
      "|  MSFT|   Microsoft Corp.| 341.07|2500000|\n",
      "|  AMZN|   Amazon.com Inc.| 139.68|2200000|\n",
      "| GOOGL|     Alphabet Inc.|2724.34|1800000|\n",
      "|  AAPL|        Apple Inc.| 175.64|3000000|\n",
      "|  TSLA|        Tesla Inc.|  890.1|2000000|\n",
      "+------+------------------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query to select all records from the test_table\n",
    "result = spark.sql(\"SELECT * FROM teststocksymbols\")\n",
    "\n",
    "# Show the results\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3850760-b863-4d23-9a7f-c463737f8bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+-------+\n",
      "|       col_name|data_type|comment|\n",
      "+---------------+---------+-------+\n",
      "|         symbol|   string|       |\n",
      "|           name|   string|       |\n",
      "|          price|   double|       |\n",
      "|         volume|      int|       |\n",
      "|               |         |       |\n",
      "| # Partitioning|         |       |\n",
      "|Not partitioned|         |       |\n",
      "+---------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe the table using Spark SQL\n",
    "spark.sql(\"DESCRIBE teststocksymbols\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a0c2843-0496-45d5-872a-04eb89263bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/08/06 23:23:25 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `default`.`teststocksymbols` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n",
      "+------+------------------+------+-------+\n",
      "|symbol|              name| price| volume|\n",
      "+------+------------------+------+-------+\n",
      "|  AAPL|        Apple Inc.|745.72| 767925|\n",
      "|  AMZN|   Amazon.com Inc.|860.83| 310173|\n",
      "| GOOGL|     Alphabet Inc.|511.09|1973201|\n",
      "|  MSFT|   Microsoft Corp.| 420.8|2969903|\n",
      "|  NVDA|NVIDIA Corporation| 51.59|3710661|\n",
      "|  TSLA|        Tesla Inc.|463.57|3072530|\n",
      "+------+------------------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Read Delta table\n",
    "df = spark.read.format(\"delta\").load(\"hdfs://namenode:8020/testlakehouse/TestStockSymbols\")\n",
    "\n",
    "# Generate random values for 'price' and 'volume'\n",
    "df_with_random_values = df \\\n",
    "    .withColumn(\"price\", F.round(F.rand() * 1000, 2)) \\\n",
    "    .withColumn(\"volume\", F.round(F.rand() * 5000000).cast(\"int\"))\n",
    "\n",
    "# Overwrite the Delta table with new random values\n",
    "df_with_random_values.write.format(\"delta\").mode(\"overwrite\").save(\"hdfs://namenode:8020/testlakehouse/TestStockSymbols\")\n",
    "\n",
    "# Register the Delta table in Spark SQL catalog again\n",
    "spark.sql(\"DROP TABLE IF EXISTS TestStockSymbols\")\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE TestStockSymbols\n",
    "    USING DELTA\n",
    "    LOCATION 'hdfs://namenode:8020/testlakehouse/TestStockSymbols'\n",
    "\"\"\")\n",
    "\n",
    "# Show the results\n",
    "result = spark.sql(\"SELECT * FROM TestStockSymbols ORDER BY symbol ASC\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3a51b42-93b1-47a5-bcb8-6c92de5ae4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describing table: teststocksymbols\n",
      "+---------------+---------+-------+\n",
      "|col_name       |data_type|comment|\n",
      "+---------------+---------+-------+\n",
      "|symbol         |string   |       |\n",
      "|name           |string   |       |\n",
      "|price          |double   |       |\n",
      "|volume         |int      |       |\n",
      "|               |         |       |\n",
      "|# Partitioning |         |       |\n",
      "|Not partitioned|         |       |\n",
      "+---------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show all tables in the current database\n",
    "tables = spark.sql(\"SHOW TABLES\").select(\"tableName\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Describe each table\n",
    "for table in tables:\n",
    "    print(f\"Describing table: {table}\")\n",
    "    description = spark.sql(f\"DESCRIBE {table}\")\n",
    "    description.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4dfd5b6-e80e-4207-baff-10dc4f6ae9d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current database: default\n"
     ]
    }
   ],
   "source": [
    "current_database = spark.sql(\"SELECT current_database()\").collect()[0][0]\n",
    "print(f\"Current database: {current_database}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2af70ccb-99f2-44b5-a942-f4044c1c32b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+------+-------+\n",
      "|symbol|              name| price| volume|\n",
      "+------+------------------+------+-------+\n",
      "|  AAPL|        Apple Inc.|745.72| 767925|\n",
      "|  AMZN|   Amazon.com Inc.|860.83| 310173|\n",
      "| GOOGL|     Alphabet Inc.|511.09|1973201|\n",
      "|  MSFT|   Microsoft Corp.| 420.8|2969903|\n",
      "|  NVDA|NVIDIA Corporation| 51.59|3710661|\n",
      "|  TSLA|        Tesla Inc.|463.57|3072530|\n",
      "+------+------------------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the results\n",
    "result = spark.sql(\"SELECT * FROM TestStockSymbols ORDER BY symbol ASC\")\n",
    "result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
